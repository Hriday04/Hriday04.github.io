# -*- coding: utf-8 -*-
"""SpotifyML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ogmSDoL3bFqedw_n9j1kTJLF1CDHP0wj

# SpotifyML
This notebook includes data preprocessing of the JSON files, and dives into a few different ways of creating the GNN.

Still in the exploratory phase, so there's no final model.

Dataset: https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge

swag
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive/', force_remount = True)
# %cd '/content/drive/MyDrive/SpotifyML'
# %pwd

import torch

def format_pytorch_version(version):
  return version.split('+')[0]

TORCH_version = torch.__version__
TORCH = format_pytorch_version(TORCH_version)

def format_cuda_version(version):
  return 'cu' + version.replace('.', '')

CUDA_version = torch.version.cuda
CUDA = format_cuda_version(CUDA_version)

#!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html
#!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html
#!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html
#!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html
#!pip install torch-geometric

"""# Data preprocessing

## extracting JSON files
"""

#!ls

import JSON_Classes
import glob
from pathlib import Path
import networkx as nx
import random
import matplotlib as plt
import torch
import torch_geometric
import numpy as np

#list
jsonList = []

folder_path = Path() / 'sampleJSONs2'

for file in folder_path.iterdir():
  # assign "file" to newVAR
  jsonfile = file
  #run processes on file
  x = JSON_Classes.JSONFile(folder_path, jsonfile.name, 0)
  x.process_files()
  #append file to list
  jsonList.append(x)

print(jsonList[3])

print(jsonList)
print(jsonList[3])
print(jsonList[3].playlists)
print(jsonList[3].playlists["playlist_0"].tracks)
#print(jsonList[3].playlists["playlist_0"].tracks['spotify:track:6cb0HzFQPN4BGADOmSzPCw'])

playlistList = []
trackList = []
playlistData = {}

for index, obj in enumerate(jsonList):
    playlistList += [x.name for x in obj.playlists.values()]
    trackList += [track.uri for playlist in obj.playlists.values() for track in list(playlist.tracks.values())]

    # Prepend a unique identifier (e.g., the file index) to each playlist key
    for key in obj.playlists:
        unique_key = f"file_{index}_{key}"
        playlistData[unique_key] = obj.playlists[key]

print(len(playlistData))
print(playlistData)

"""## creating graph G"""

G = nx.Graph()
# G.add_nodes_from(playlistList)
# G.add_nodes_from(trackList)

G.add_nodes_from([
    (p, {'name':p, "node_type": "playlist"}) for p in playlistData
])
G.add_nodes_from([
    (t, {'name':t, "node_type": "track"}) for t in trackList
])



edge_list = []
for p_name, playlist in playlistData.items():
  edge_list += [(p_name, t) for t in playlist.tracks]
G.add_edges_from(edge_list)

# # Iterate through each playlist and its tracks to create edges
# for playlist_key, playlist in playlistData.items():
#     for track in playlist.tracks.values():
#         # add edge to an edge list?
#         G.add_edge(playlist_key, track.uri)

print(G.number_of_nodes())
print(G.number_of_edges())

list(G.nodes)[:5]

G.nodes['file_5_playlist_970']

print(list(G.edges())[:5])

# Implement Dimensionality Reduction:
# Select only nodes with degree >= 30
k = 20
G = nx.k_core(G, k)
print(f"Number of Nodes: {G.number_of_nodes()} \nNumber of Edges: {G.number_of_edges()}")

sample_edge_list = list(G.edges())
print(sample_edge_list[:5])

"""## subset of G creation/visualization"""

random.seed(1729)
rand_nodes = random.sample(list(G.nodes()), 100)
color_map = {"playlist": 0, "track": 1}
sub_G = G.subgraph(rand_nodes)
largest_cc_sm = max(nx.connected_components(sub_G.to_undirected()), key=len)
sub_G = nx.Graph(sub_G.subgraph(largest_cc_sm))

print(attr["name"] for attr in sub_G.nodes(data = True))
node_colors = [color_map[attr["node_type"]] for (id, attr) in sub_G.nodes(data=True)]

nx.draw(sub_G,
        node_size = 30,
        width = 2,
        edge_color=(0, 0, 0, 0.1),
        node_color=node_colors)

# I need colorings to make sure everything is lined up properly here.
# It looks right though, so who really knows???
top = nx.bipartite.sets(sub_G)[0]
pos = nx.bipartite_layout(sub_G, top)
nx.draw(sub_G,
        pos=pos,
        node_size = 30,
        width = 3,
        edge_color=(0, 0, 0, 0.1),
        node_color=node_colors,
        with_labels=True #ugly, i know, but you get the point
        )

edges = sub_G.edges()
print(edges)

n_nodes, n_edges = G.number_of_nodes(), G.number_of_edges()

sorted_nodes = sorted(list(G.nodes()))

node2id = dict(zip(sorted_nodes, np.arange(n_nodes)))
id2node = dict(zip(np.arange(n_nodes), sorted_nodes))

G = nx.relabel_nodes(G, node2id)

# Keep track of playlists, tracks we have
playlists_idx = [i for i, v in enumerate(node2id.keys()) if "playlist" in v]
tracks_idx = [i for i, v in enumerate(node2id.keys()) if "track" in v]

n_playlists = np.max(playlists_idx) + 1
n_tracks = n_nodes - n_playlists

n_playlists, n_tracks

num_nodes = n_playlists +  n_tracks
edge_index = torch.Tensor(np.array(G.edges()).T)
graph_data = torch_geometric.data.Data(edge_index = edge_index, num_nodes = num_nodes)

num_playlists = len([node_id for node_id, attr in sub_G.nodes(data=True) if attr.get("node_type") == 'playlist'])
print(num_playlists)

num_tracks = len([node_id for node_id, attr in sub_G.nodes(data=True) if attr.get("node_type") == 'track'])
print(num_tracks)

#making sure it has one connected component
from networkx.algorithms.components import is_connected
is_connected(G)

"""# Modified LightGCN from article

## generating train/test split with DeepSnap
"""

!pip install -q git+https://github.com/snap-stanford/deepsnap.git

import deepsnap
from deepsnap.graph import Graph
from deepsnap.batch import Batch
from deepsnap.dataset import GraphDataset
from deepsnap.hetero_gnn import forward_op
from deepsnap.hetero_graph import HeteroGraph
from sklearn.metrics import f1_score, roc_auc_score

task = 'link_pred'
dataset = GraphDataset([G], task=task, edge_train_mode='disjoint')

print(f'The dataset has {dataset.num_edges[0]} edges.')

# Split the dataset
dataset_train, dataset_val, dataset_test = dataset.split(transductive=True, split_ratio=[0.8, 0.1, 0.1])

num_train_edges = dataset_train[0].edge_label_index.shape[1]
num_val_edges = dataset_val[0].edge_label_index.shape[1]
num_test_edges = dataset_test[0].edge_label_index.shape[1]

print("Train set has {} supervision (positive) edges".format(num_train_edges // 2))
print("Validation set has {} supervision (positive) edges".format(num_val_edges // 2))
print("Test set has {} supervision (positive) edges".format(num_test_edges // 2))

print("Train set has {} message passing edges".format(dataset_train[0].edge_index.shape[1]))
print("Validation set has {} message passing edges".format(dataset_val[0].edge_index.shape[1]))
print("Test set has {} message passing edges".format(dataset_test[0].edge_index.shape[1]))

"""## LightGCN model building"""

# imports for LightGCN- copy/pasted, will be repeats of earlier imports
import torch
import torch_scatter
import torch.nn as nn
import torch.nn.functional as F

import torch_geometric.nn as pyg_nn
import torch_geometric.utils as pyg_utils

from torch import Tensor
from typing import Union, Tuple, Optional
from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType, OptTensor)

from torch.nn import Parameter, Linear
from torch_sparse import SparseTensor, set_diag
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.utils import remove_self_loops, add_self_loops, softmax

import copy
from copy import deepcopy

class LightGCNConv(MessagePassing):
    def __init__(self, in_channels, out_channels, normalize = True,
                 bias = False, **kwargs):
        super(LightGCNConv, self).__init__(**kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.normalize = normalize

    def forward(self, x, edge_index, size = None):
        out = self.propagate(edge_index, x=(x, x))
        return out

    def message(self, x_j):
        out = x_j
        return out

    def aggregate(self, inputs, index, dim_size = None):
        node_dim = self.node_dim
        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce='mean')
        return out

class LightGCN(torch.nn.Module):
    def __init__(self, train_data, num_layers, emb_size=16, initialize_with_words=False):
        super(LightGCN, self).__init__()
        self.convs = nn.ModuleList()
        assert (num_layers >= 1), 'Number of layers is not >=1'
        for l in range(num_layers):
            self.convs.append(LightGCNConv(input_dim, input_dim))

        # Initialize using custom embeddings if provided
        num_nodes = train_data.node_label_index.size()[0]
        self.embeddings = nn.Embedding(num_nodes, emb_size)
        if initialize_with_words:
            self.embeddings.weight.data.copy_(train_datanode_features)

        self.loss_fn = nn.BCELoss()
        self.num_layers = num_layers
        self.emb_size = emb_size
        self.num_modes = num_nodes

    def forward(self, data):
        edge_index, edge_label_index, node_label_index = data.edge_index, data.edge_label_index, data.node_label_index
        layer_embeddings = []

        x = self.embeddings(node_label_index)
        mean_layer = x

        # We take an average of ever layer's node embeddings
        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
            mean_layer += x

        mean_layer /= 4

        # Prediction head is simply dot product
        nodes_first = torch.index_select(x, 0, edge_label_index[0,:].long())
        nodes_second = torch.index_select(x, 0, edge_label_index[1,:].long())

        # Since we don't want a rank output, we create a sigmoid of the dot product
        out = torch.sum(nodes_first * nodes_second, dim=-1) # FOR RANKING
        pred = torch.sigmoid(out)

        return torch.flatten(pred)

    def loss(self, pred, label):
        return self.loss_fn(pred, label)

"""## train/test model

"""

import warnings
warnings.filterwarnings('ignore')

args = {
    'device' : 'cuda' if torch.cuda.is_available() else 'cpu',
    'num_layers' : 3,
    'emb_size' : 32,
    'epochs' : 1,
    'weight_decay': 1e-5,
    'lr': 0.01,
    'epochs': 300
}

datasets = {
    'train': dataset_train[0],
    'val': dataset_val[0],
    'test': dataset_test[0]
}

input_dim = datasets['train'].num_node_features
print(input_dim, args)

datasets['train'].to(args['device'])
datasets['val'].to(args['device'])
datasets['test'].to(args['device'])

"""train/test functions"""

losses = []

def train(model, optimizer, args):
    val_max = 0
    best_model = model

    for epoch in range(1, args['epochs'] + 1):
        datasets['train'].to(args["device"])
        model.train()
        optimizer.zero_grad()
        pred = model(datasets['train'])
        loss = model.loss(pred, datasets['train'].edge_label.type(pred.dtype))

        loss.backward()
        optimizer.step()

        log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Loss: {:.5f}, Val Loss: {:.5f}'
        score_train, train_loss = test(model, 'train', args)
        score_val, val_loss = test(model, 'val', args)
        score_test, test_loss = test(model, 'test', args)

        losses.append((train_loss, val_loss))

        print(log.format(epoch, score_train, score_val, score_test, train_loss, val_loss))
        if val_max < score_val:
            val_max = score_val
            best_model = copy.deepcopy(model)

    return best_model

def test(model, mode, args):
    model.eval()
    score = 0
    loss_score = 0

    data = datasets[mode]
    data.to(args["device"])

    pred = model(data)
    loss = model.loss(pred, data.edge_label.type(pred.dtype))
    score += roc_auc_score(data.edge_label.flatten().cpu().numpy(), pred.flatten().data.cpu().numpy())
    loss_score += loss.item()

    return score, loss_score

"""start training??"""

model = LightGCN(datasets['train'], args['num_layers'], emb_size=args['emb_size']).to(args['device'])
optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])

best_model = train(model, optimizer, args)
log = "Train: {:.4f}, Val: {:.4f}, Test: {:.4f}, Val Loss: {:.5f}, Test Loss: {:.5f}"
best_train_roc, train_loss = test(best_model, 'train', args)
best_val_roc, val_loss = test(best_model, 'val', args)
best_test_roc, test_loss = test(best_model, 'test', args)
print(log.format(best_train_roc, best_val_roc, best_test_roc, train_loss, val_loss, test_loss))

"""## evaluation"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

def plot_learning_curve(losses, title):
    train_loss, val_loss = zip(*losses)
    steps = list(range(1, len(train_loss) + 1))

    min_val_loss = np.round(np.min(val_loss), 3)

    plt.figure(figsize=(16, 6))
    plt.plot(steps, train_loss, '-r', label='Training Loss')
    plt.plot(steps, val_loss, '-b', label='Validation Loss')
    plt.hlines(min_val_loss, 1, 300, colors='k', linestyles='dotted', label='Min Validation Loss: {}'.format(min_val_loss))

    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.ylim((0.58, 0.71))
    plt.title(title)
    plt.legend(loc='upper right')
    plt.title(title)

    return plt

plot_learning_curve(losses, 'LightGCN on Sample Spotify Data')

"""# exploring models.LightGCN from pytorch

[model using LGConv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LightGCN.html?highlight=lgconv)
"""

LightGCN = torch_geometric.nn.models.LightGCN

"""## pytorch's example"""

import os.path as osp

import torch
from tqdm import tqdm

from torch_geometric.datasets import AmazonBook
from torch_geometric.nn import LightGCN
from torch_geometric.utils import degree

"""### data
was gonna say data preprocessing but there really isn't much "processing" being done... they so convienently have a perfectly ready dataset ðŸ˜Š ðŸ™ƒ ðŸ˜  ðŸ³ âœˆ ðŸ’£ that helps me know what to do with mine!
"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

path = osp.join( '..', 'data', 'Amazon')
dataset = AmazonBook(path)
data = dataset[0]
num_users, num_books = data['user'].num_nodes, data['book'].num_nodes
data = data.to_homogeneous().to(device)

dataset[0]

"""I honestly don't know what's happening in the code section below this. I see the model is being defined and the optimizer set, but what's the rest?? train/test split?"""

# Use all message passing edges as training labels:
batch_size = 8192
mask = data.edge_index[0] < data.edge_index[1]
train_edge_label_index = data.edge_index[:, mask]
train_loader = torch.utils.data.DataLoader(
    range(train_edge_label_index.size(1)),
    shuffle=True,
    batch_size=batch_size,
)

model = LightGCN(
    num_nodes=data.num_nodes,
    embedding_dim=64,
    num_layers=2,
).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

"""### testing/training"""

def train():
    total_loss = total_examples = 0

    for index in tqdm(train_loader):
        # Sample positive and negative labels.
        pos_edge_label_index = train_edge_label_index[:, index]
        neg_edge_label_index = torch.stack([
            pos_edge_label_index[0],
            torch.randint(num_users, num_users + num_books,
                          (index.numel(), ), device=device)
        ], dim=0)
        edge_label_index = torch.cat([
            pos_edge_label_index,
            neg_edge_label_index,
        ], dim=1)

        optimizer.zero_grad()
        pos_rank, neg_rank = model(data.edge_index, edge_label_index).chunk(2)

        loss = model.recommendation_loss(
            pos_rank,
            neg_rank,
            node_id=edge_label_index.unique(),
        )
        loss.backward()
        optimizer.step()

        total_loss += float(loss) * pos_rank.numel()
        total_examples += pos_rank.numel()

    return total_loss / total_examples

@torch.no_grad() # <-- "context-manager that disables gradient calculation"
def test(k: int):
    emb = model.get_embedding(data.edge_index)
    user_emb, book_emb = emb[:num_users], emb[num_users:]

    precision = recall = total_examples = 0
    for start in range(0, num_users, batch_size):
        end = start + batch_size
        logits = user_emb[start:end] @ book_emb.t()

        # Exclude training edges:
        mask = ((train_edge_label_index[0] >= start) &
                (train_edge_label_index[0] < end))
        logits[train_edge_label_index[0, mask] - start,
               train_edge_label_index[1, mask] - num_users] = float('-inf')

        # Computing precision and recall:
        ground_truth = torch.zeros_like(logits, dtype=torch.bool)
        mask = ((data.edge_label_index[0] >= start) &
                (data.edge_label_index[0] < end))
        ground_truth[data.edge_label_index[0, mask] - start,
                     data.edge_label_index[1, mask] - num_users] = True
        node_count = degree(data.edge_label_index[0, mask] - start,
                            num_nodes=logits.size(0))

        topk_index = logits.topk(k, dim=-1).indices
        isin_mat = ground_truth.gather(1, topk_index)

        precision += float((isin_mat.sum(dim=-1) / k).sum())
        recall += float((isin_mat.sum(dim=-1) / node_count.clamp(1e-6)).sum())
        total_examples += int((node_count > 0).sum())

    return precision / total_examples, recall / total_examples

for epoch in range(1, 101):
    loss = train()
    precision, recall = test(k=20)
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Precision@20: '
          f'{precision:.4f}, Recall@20: {recall:.4f}')

"""## me trying to figure shit out ðŸ˜­

"""

#convert our graph data to HeteroData to plug into the above model??

import torch
from torch_geometric.data import HeteroData

"""Ok, this is NOT working with colab for some reason.

Maybe not the most efficent way to put the data too?

"""

# Example edge list
#edge_list = [('user1', 'item1'), ('user2', 'item2'), ('user3', 'item1')]

# Convert node IDs to integer indices for PyTorch Geometric
# This step depends on how your node IDs are formatted
# Here's a simple way to encode string IDs as integers
unique_nodes = list(set(sum(sample_edge_list, ())))
node_mapping = {node_id: idx for idx, node_id in enumerate(unique_nodes)}
edges = [(node_mapping[src], node_mapping[dst]) for src, dst in sample_edge_list]

# Separate source and destination nodes
src_nodes, dst_nodes = zip(*edges)

# Convert to tensors
src_tensor = torch.tensor(src_nodes, dtype=torch.long)
dst_tensor = torch.tensor(dst_nodes, dtype=torch.long)

# Create HeteroData object
data = HeteroData()

# Add edges to the HeteroData object
# Assuming 'user' and 'item' are the node types
data['user', 'interacts', 'item'].edge_index = torch.stack([src_tensor, dst_tensor], dim=0)

# Now, 'data' is your HeteroData object with the edges added

data

"""# LightGCN from other article
Section of stuff from https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-*d8301178e377*

In the article they go over NGCF so I'm going to learn some basics of NGCF but in here I'm only doing LightGCN

NGCF"""

# Standard library imports
import random
import time

# Third-party imports
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
pd.set_option('display.max_colwidth', None)

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
# from torch.utils.data import Dataset, DataLoader
import torch_geometric
from torch_geometric.nn.conv import MessagePassing
from torch_geometric.utils import degree

from tqdm.notebook import tqdm
from sklearn import preprocessing as pp
from sklearn.model_selection import train_test_split
import scipy.sparse as sp

torch_geometric.__version__

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device

"""## data preprocessing
Using dataframes and using dataLoader to turn into tensors?
"""

df = pd.DataFrame(sample_edge_list, columns=['Playlist', 'Song'])

df.head()

# Perform a 80/20 train-test split on the interactions in the dataset
train, test = train_test_split(df.values, test_size=0.2, random_state=16)
train_df = pd.DataFrame(train, columns=df.columns)
test_df = pd.DataFrame(test, columns=df.columns)

print("Train Size  : ", len(train_df))
print("Test Size : ", len(test_df))

le_playlist = pp.LabelEncoder()
le_song = pp.LabelEncoder()
train_df['playlist_idx'] = le_playlist.fit_transform(train_df['Playlist'].values)
train_df['song_idx'] = le_song.fit_transform(train_df['Song'].values)

train_playlist = train_df['Playlist'].unique()
train_song = train_df['Song'].unique()

print(len(train_playlist), len(train_song))

test_df = test_df[
  (test_df['Playlist'].isin(train_playlist)) & \
  (test_df['Song'].isin(train_song))
]
print(len(test))

test_df['playlist_idx'] = le_playlist.transform(test_df['Playlist'].values)
test_df['song_idx'] = le_song.transform(test_df['Song'].values)

n_playlists = train_df['playlist_idx'].nunique()
n_songs = train_df['song_idx'].nunique()
print("Number of unique Playlists : ", n_playlists)
print("Number of unique Songs : ", n_songs)

def data_loader(data, batch_size, n_plylst, n_sng):

    def sample_neg(x):
        while True:
            neg_id = random.randint(0, n_sng - 1)
            if neg_id not in x:
                return neg_id

    interected_songs_df = data.groupby('playlist_idx')['song_idx'].apply(list).reset_index()
    indices = [x for x in range(n_plylst)]

    if n_plylst < batch_size:
        playlists = [random.choice(indices) for _ in range(batch_size)]
    else:
        playlists = random.sample(indices, batch_size)
    playlists.sort()
    playlist_df = pd.DataFrame(playlists,columns = ['Playlist'])

    interected_songs_df = pd.merge(interected_songs_df, playlist_df, how = 'right', left_on = 'playlist_idx', right_on = 'Playlist')
    pos_songs = interected_songs_df['song_idx'].apply(lambda x : random.choice(x)).values
    neg_songs = interected_songs_df['song_idx'].apply(lambda x: sample_neg(x)).values

    return (
        torch.LongTensor(list(playlists)).to(device),
        torch.LongTensor(list(pos_songs)).to(device) + n_plylst,
        torch.LongTensor(list(neg_songs)).to(device) + n_plylst
    )

data_loader(train_df, 16, n_playlists, n_songs)

p_t = torch.LongTensor(train_df.playlist_idx)
s_t = torch.LongTensor(train_df.song_idx) + n_playlists

train_edge_index = torch.stack((
  torch.cat([p_t, s_t]),
  torch.cat([s_t, p_t])
)).to(device)
train_edge_index

train_edge_index[:,-1], train_edge_index[:, 0]

train_edge_index[:, len(train)-1], train_edge_index[:, len(train)]

"""## Model building"""

class LightGCNConv(MessagePassing):
  def __init__(self, **kwargs):
    super().__init__(aggr='add')

  def forward(self, x, edge_index):
    # Compute normalization
    from_, to_ = edge_index
    deg = degree(to_, x.size(0), dtype=x.dtype)
    deg_inv_sqrt = deg.pow(-0.5)
    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]

    # Start propagating messages (no update after aggregation)
    return self.propagate(edge_index, x=x, norm=norm)

  def message(self, x_j, norm):
    return norm.view(-1, 1) * x_j

"""testing on a small tensor"""

test_x = torch.Tensor(np.eye(5))
test_edge_index = torch.LongTensor(np.array([
  [0, 0, 1, 1, 2, 3, 3, 4],
  [2, 3, 3, 4, 0, 0, 1, 1]
]))

LightGCNConv()(test_x, test_edge_index)

"""This was used for both NGCF and LightGCN. If I want to adopt this, I'll have to remove the NGCF stuff."""

# class RecSysGNN(nn.Module):
#   def __init__(
#       self,
#       latent_dim,
#       num_layers,
#       num_playlists,
#       num_songs,
#       model, # 'NGCF' or 'LightGCN'
#       dropout=0.1 # Only used in NGCF
#   ):
#     super(RecSysGNN, self).__init__()

#     assert (model == 'NGCF' or model == 'LightGCN'), \
#         'Model must be NGCF or LightGCN'
#     self.model = model
#     self.embedding = nn.Embedding(num_playlists + num_songs, latent_dim)

#     if self.model == 'NGCF':
#       self.convs = nn.ModuleList(
#         NGCFConv(latent_dim, dropout=dropout) for _ in range(num_layers)
#       )
#     else:
#       self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))

#     self.init_parameters()


#   def init_parameters(self):
#     if self.model == 'NGCF':
#       nn.init.xavier_uniform_(self.embedding.weight, gain=1)
#     else:
#       # Authors of LightGCN report higher results with normal initialization
#       nn.init.normal_(self.embedding.weight, std=0.1)


#   def forward(self, edge_index):
#     emb0 = self.embedding.weight
#     embs = [emb0]

#     emb = emb0
#     for conv in self.convs:
#       emb = conv(x=emb, edge_index=edge_index)
#       embs.append(emb)

#     out = (
#       torch.cat(embs, dim=-1) if self.model == 'NGCF'
#       else torch.mean(torch.stack(embs, dim=0), dim=0)
#     )

#     return emb0, out


#   def encode_minibatch(self, playlists, pos_songs, neg_songs, edge_index):
#     emb0, out = self(edge_index)
#     return (
#         out[playlists],
#         out[pos_songs],
#         out[neg_songs],
#         emb0[playlists],
#         emb0[pos_songs],
#         emb0[neg_songs]
#     )

class RecSysGNN(nn.Module):
  def __init__(
      self,
      latent_dim,
      num_layers,
      num_playlists,
      num_songs
      ):
    super(RecSysGNN, self).__init__()

    self.embedding = nn.Embedding(num_playlists + num_songs, latent_dim)

    self.convs = nn.ModuleList(LightGCNConv() for _ in range(num_layers))

    self.init_parameters()


  def init_parameters(self):
    # Authors of LightGCN report higher results with normal initialization
    nn.init.normal_(self.embedding.weight, std=0.1)


  def forward(self, edge_index):
    emb0 = self.embedding.weight
    embs = [emb0]

    emb = emb0
    for conv in self.convs:
      emb = conv(x=emb, edge_index=edge_index)
      embs.append(emb)

    out = (
      torch.mean(torch.stack(embs, dim=0), dim=0)
    )

    return emb0, out


  def encode_minibatch(self, playlists, pos_songs, neg_songs, edge_index):
    emb0, out = self(edge_index)
    return (
        out[playlists],
        out[pos_songs],
        out[neg_songs],
        emb0[playlists],
        emb0[pos_songs],
        emb0[neg_songs]
    )

def compute_bpr_loss(playlists, playlists_emb, pos_emb, neg_emb, playlist_emb0,  pos_emb0, neg_emb0):
  # compute loss from initial embeddings, used for regulization
  reg_loss = (1 / 2) * (
    playlist_emb0.norm().pow(2) +
    pos_emb0.norm().pow(2)  +
    neg_emb0.norm().pow(2)
  ) / float(len(playlists))

  # compute BPR loss from user, positive item, and negative item embeddings
  pos_scores = torch.mul(playlists_emb, pos_emb).sum(dim=1)
  neg_scores = torch.mul(playlists_emb, neg_emb).sum(dim=1)

  bpr_loss = torch.mean(F.softplus(neg_scores - pos_scores))

  return bpr_loss, reg_loss

def get_metrics(playlist_Embed_wts, song_Embed_wts, n_playlists, n_songs, train_data, test_data, K):
  test_playlist_ids = torch.LongTensor(test_data['playlist_idx'].unique())
  # compute the score of all user-item pairs
  relevance_score = torch.matmul(playlist_Embed_wts, torch.transpose(song_Embed_wts,0, 1))

  # create dense tensor of all user-item interactions
  i = torch.stack((
    torch.LongTensor(train_df['playlist_idx'].values),
    torch.LongTensor(train_df['song_idx'].values)
  ))
  v = torch.ones((len(train_df)), dtype=torch.float64)
  interactions_t = torch.sparse.FloatTensor(i, v, (n_playlists, n_songs))\
      .to_dense().to(device)

  # mask out training user-item interactions from metric computation
  relevance_score = torch.mul(relevance_score, (1 - interactions_t))

  # compute top scoring items for each user
  topk_relevance_indices = torch.topk(relevance_score, K).indices
  topk_relevance_indices_df = pd.DataFrame(topk_relevance_indices.cpu().numpy(),columns =['top_indx_'+str(x+1) for x in range(K)])
  topk_relevance_indices_df['Playlist'] = topk_relevance_indices_df.index
  topk_relevance_indices_df['top_rlvnt_sng'] = topk_relevance_indices_df[['top_indx_'+str(x+1) for x in range(K)]].values.tolist()
  topk_relevance_indices_df = topk_relevance_indices_df[['Playlist','top_rlvnt_sng']]

  # measure overlap between recommended (top-scoring) and held-out user-item
  # interactions
  test_interacted_songs = test_data.groupby('playlist_idx')['song_idx'].apply(list).reset_index()
  metrics_df = pd.merge(test_interacted_songs,topk_relevance_indices_df, how= 'left', left_on = 'playlist_idx',right_on = ['Playlist'])
  metrics_df['intrsctn_sng'] = [list(set(a).intersection(b)) for a, b in zip(metrics_df.song_idx, metrics_df.top_rlvnt_sng)]

  metrics_df['recall'] = metrics_df.apply(lambda x : len(x['intrsctn_sng'])/len(x['song_idx']), axis = 1)
  metrics_df['precision'] = metrics_df.apply(lambda x : len(x['intrsctn_sng'])/K, axis = 1)

  return metrics_df['recall'].mean(), metrics_df['precision'].mean()

"""parameters"""

latent_dim = 64
n_layers = 3

EPOCHS = 50
BATCH_SIZE = 1024
DECAY = 0.0001
LR = 0.005
K = 20

"""## train/testing!!"""

def train_and_eval(model, optimizer, train_df):
  loss_list_epoch = []
  bpr_loss_list_epoch = []
  reg_loss_list_epoch = []

  recall_list = []
  precision_list = []

  for epoch in tqdm(range(EPOCHS)):
      n_batch = int(len(train)/BATCH_SIZE)

      final_loss_list = []
      bpr_loss_list = []
      reg_loss_list = []

      model.train()
      for batch_idx in range(n_batch):

          optimizer.zero_grad()

          playlists, pos_songs, neg_songs = data_loader(train_df, BATCH_SIZE, n_playlists, n_songs)
          playlists_emb, pos_emb, neg_emb, playlistEmb0,  posEmb0, negEmb0 = model.encode_minibatch(playlists, pos_songs, neg_songs, train_edge_index)

          bpr_loss, reg_loss = compute_bpr_loss(
            playlists, playlists_emb, pos_emb, neg_emb, playlistEmb0,  posEmb0, negEmb0
          )
          reg_loss = DECAY * reg_loss
          final_loss = bpr_loss + reg_loss

          final_loss.backward()
          optimizer.step()

          final_loss_list.append(final_loss.item())
          bpr_loss_list.append(bpr_loss.item())
          reg_loss_list.append(reg_loss.item())

      model.eval()
      with torch.no_grad():
          _, out = model(train_edge_index)
          final_playlists_Embed, final_song_Embed = torch.split(out, (n_playlists, n_songs))
          test_topK_recall,  test_topK_precision = get_metrics(
            final_playlists_Embed, final_song_Embed, n_playlists, n_songs, train_df, test_df, K
          )

      loss_list_epoch.append(round(np.mean(final_loss_list),4))
      bpr_loss_list_epoch.append(round(np.mean(bpr_loss_list),4))
      reg_loss_list_epoch.append(round(np.mean(reg_loss_list),4))

      recall_list.append(round(test_topK_recall,4))
      precision_list.append(round(test_topK_precision,4))

  return (
    loss_list_epoch,
    bpr_loss_list_epoch,
    reg_loss_list_epoch,
    recall_list,
    precision_list
  )

lightgcn = RecSysGNN(
  latent_dim=latent_dim,
  num_layers=n_layers,
  num_playlists=n_playlists,
  num_songs=n_songs
)
lightgcn.to(device)

optimizer = torch.optim.Adam(lightgcn.parameters(), lr=LR)
print("Size of Learnable Embedding : ", [x.shape for x in list(lightgcn.parameters())])

"""I apparently decided to run it on the whole graph (after dimensionality reduction) and now I have to commit to it... Runtime ~1hr??"""

light_loss, light_bpr, light_reg, light_recall, light_precision = train_and_eval(lightgcn, optimizer, train_df)

epoch_list = [(i+1) for i in range(EPOCHS)]

import matplotlib.pyplot as plt

plt.plot(epoch_list, light_loss, label='Total Training Loss')
plt.plot(epoch_list, light_bpr, label='BPR Training Loss')
plt.plot(epoch_list, light_reg, label='Reg Training Loss')

plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.plot(epoch_list, light_recall, label='Recall')
plt.plot(epoch_list, light_precision, label='Precision')
plt.xlabel('Epoch')
plt.ylabel('Metrics')
plt.legend()

# Save the entire model
torch.save(lightgcn, 'model.pth')

# Save only the state dictionary
torch.save(lightgcn.state_dict(), 'model_state_dict.pth')

"""## finding playlist to test results with"""

oneJSON = []

folder_path = Path() / 'testJSON'

for file in folder_path.iterdir():
  # assign "file" to newVAR
  jsonfile = file
  #run processes on file
  x = JSON_Classes.JSONFile(folder_path, jsonfile.name, 0)
  x.process_files()
  #append file to list
  oneJSON.append(x)

oneJSON

playlistList2 = []
trackList2 = []
playlistData2 = {}

for index, obj in enumerate(oneJSON):
    playlistList2 += [x.name for x in obj.playlists.values()]
    trackList2 += [track.uri for playlist in obj.playlists.values() for track in list(playlist.tracks.values())]

    # Prepend a unique identifier (e.g., the file index) to each playlist key
    for key in obj.playlists:
        unique_key = f"test_file_{key}"
        playlistData2[unique_key] = obj.playlists[key]

print(playlistList2[:5])
print(trackList2[:5])
print(playlistData2)

H = nx.Graph()
# G.add_nodes_from(playlistList)
# G.add_nodes_from(trackList)

H.add_nodes_from([
    (p, {'name':p, "node_type": "playlist"}) for p in playlistData2
])
H.add_nodes_from([
    (t, {'name':t, "node_type": "track"}) for t in trackList2
])



edge_list2 = []
for p_name, playlist in playlistData2.items():
  edge_list2 += [(p_name, t) for t in playlist.tracks]
H.add_edges_from(edge_list2)

# # Iterate through each playlist and its tracks to create edges
# for playlist_key, playlist in playlistData.items():
#     for track in playlist.tracks.values():
#         # add edge to an edge list?
#         G.add_edge(playlist_key, track.uri)

print(H.number_of_nodes())
print(H.number_of_edges())

# Step 1: Identify nodes in H that are not in G
nodes_to_remove = [node for node in H.nodes() if node not in G.nodes()]
print(len(nodes_to_remove))

remove_nodes = []
for node in nodes_to_remove:
  if 'track' in node:
    remove_nodes.append(node)

print(remove_nodes[:5])

# Step 2: Remove these nodes from H
H.remove_nodes_from(remove_nodes)

print(H.number_of_nodes())
print(H.number_of_edges())

sample_edge_list2 = list(H.edges())
print(sample_edge_list2[:5])

df2 = pd.DataFrame(sample_edge_list2, columns=['Playlist', 'Song'])

df2['Playlist'].value_counts()

test_playlist = playlistData2['test_file_playlist_872']

type(test_playlist)

test_playlist_edges = df2[df2['Playlist'] == 'test_file_playlist_872']

test_playlist_edges

songs_in_playlist = list(test_playlist_edges['Song'])

songs_in_playlist[:5]

"""formatting data to input"""

songs_in_playlist[]

"""## Fetching pretrained model and creating song recs"""

# load model
model = torch.load('model.pth')
model.eval()